{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482cd64d",
   "metadata": {},
   "source": [
    "# Analisis Anomali Network Menggunakan FP-Growth dan Association Rules\n",
    "\n",
    "## Deskripsi Proyek\n",
    "Notebook ini menganalisis log jaringan untuk mendeteksi anomali menggunakan algoritma **FP-Growth** (Frequent Pattern Growth) dan **Association Rules**. Tujuan utama adalah menemukan pola hubungan antara kondisi jaringan dan diagnosis anomali.\n",
    "\n",
    "## Struktur Analisis\n",
    "1. **Encoding Data**: Mengonversi data log menjadi format transaksi yang dapat dianalisis\n",
    "2. **FP-Growth Algorithm**: Menemukan pola frekuen dengan threshold minimum support\n",
    "3. **Association Rules**: Menghasilkan aturan asosiasi untuk prediksi diagnosis\n",
    "4. **Filtering & Visualization**: Menyaring aturan yang relevan dan menampilkan hasil akhir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b63ad",
   "metadata": {},
   "source": [
    "## Tahap 1: Import Library dan Persiapan Data\n",
    "\n",
    "Pada tahap ini, kami mengimpor library yang diperlukan untuk analisis frequent pattern mining dan memuat dataset yang sudah dibersihkan dari tahap preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c967ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "import pandas as pd\n",
    "\n",
    "# Import cleaned data dari hasil preprocessing\n",
    "df_cleaned = pd.read_csv('../Data/Data_Siap_Mining.csv')\n",
    "print(f\"Dataset berhasil dimuat: {df_cleaned.shape[0]} baris, {df_cleaned.shape[1]} kolom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba09efe3",
   "metadata": {},
   "source": [
    "## Tahap 2: Encoding Data dan Perhitungan FP-Growth\n",
    "\n",
    "### Proses Encoding\n",
    "- **TransactionEncoder**: Mengkonversi data log dari format text menjadi format transaksi (one-hot encoded)\n",
    "- Setiap item dalam 'items' column diubah menjadi kolom boolean terpisah\n",
    "- Output: DataFrame `df_encoded` dengan nilai True/False untuk setiap atribut\n",
    "\n",
    "### Perhitungan Support\n",
    "- **Minimum Support**: Threshold minimum untuk pola yang dianggap \"sering\" terjadi\n",
    "- **MIN_SUPPORT_COUNT = 20**: Pola harus muncul minimal 20 kali dalam dataset\n",
    "- **min_support_pct**: Persentase support dihitung dari total jumlah transaksi\n",
    "\n",
    "### Algoritma FP-Growth\n",
    "- **fpgrowth**: Algoritma efisien untuk mining pola frekuen\n",
    "- Lebih cepat dari Apriori karena menggunakan FP-tree structure\n",
    "- Output: `frequent_itemsets` berisi semua pola yang memenuhi threshold\n",
    "\n",
    "### Association Rules\n",
    "- Menghasilkan aturan IF-THEN dari pola frekuen\n",
    "- **min_threshold = 0.6**: Hanya aturan dengan confidence ≥ 60% yang dipertahankan\n",
    "- Metrik yang dihitung: support, confidence, lift, dsb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac89e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 1: ENCODING DATA =====\n",
    "# Inisialisasi TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "\n",
    "# Konversi kolom 'items' dari string menjadi list dan lakukan fit-transform\n",
    "items_list = df_cleaned['items'].apply(lambda x: eval(x)).tolist()\n",
    "te_ary = te.fit(items_list).transform(items_list)\n",
    "\n",
    "# Buat DataFrame dengan kolom yang sesuai\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "print(f\"\\n✓ Data berhasil di-encode:\")\n",
    "print(f\"  - Shape: {df_encoded.shape}\")\n",
    "print(f\"  - Atribut unik: {len(df_encoded.columns)}\")\n",
    "print(f\"\\nSample data (5 baris pertama):\\n{df_encoded.head()}\")\n",
    "\n",
    "# ===== STEP 2: FP-GROWTH ALGORITHM =====\n",
    "# Hitung minimum support percentage\n",
    "MIN_SUPPORT_COUNT = 20\n",
    "min_support_pct = MIN_SUPPORT_COUNT / len(df_encoded)\n",
    "print(f\"\\n✓ Konfigurasi Minimum Support:\")\n",
    "print(f\"  - MIN_SUPPORT_COUNT: {MIN_SUPPORT_COUNT}\")\n",
    "print(f\"  - Total Transaksi: {len(df_encoded)}\")\n",
    "print(f\"  - min_support_pct: {min_support_pct:.4f} ({min_support_pct*100:.2f}%)\")\n",
    "\n",
    "# Jalankan FP-Growth\n",
    "frequent_itemsets = fpgrowth(df_encoded, min_support=min_support_pct, use_colnames=True)\n",
    "print(f\"\\n✓ FP-Growth selesai:\")\n",
    "print(f\"  - Pola frekuen ditemukan: {len(frequent_itemsets)}\")\n",
    "print(f\"\\nTop 5 frequent itemsets:\\n{frequent_itemsets.sort_values('support', ascending=False).head()}\")\n",
    "\n",
    "# ===== STEP 3: GENERATE ASSOCIATION RULES =====\n",
    "MIN_CONFIDENCE = 0.6\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=MIN_CONFIDENCE)\n",
    "print(f\"\\n✓ Association Rules berhasil dibuat:\")\n",
    "print(f\"  - MIN_CONFIDENCE: {MIN_CONFIDENCE}\")\n",
    "print(f\"  - Jumlah rules yang dihasilkan: {len(rules)}\")\n",
    "print(f\"\\nMetrik yang tersedia: {list(rules.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e002",
   "metadata": {},
   "source": [
    "## Tahap 3: Penyaringan dan Tampilan Hasil Akhir\n",
    "\n",
    "### Konsep Filtering\n",
    "Dari semua association rules yang dihasilkan, kita hanya ingin menyimpan rules yang:\n",
    "- **Consequent (Kesimpulan)**: Harus berupa diagnosis/label anomali\n",
    "  - NORMAL: Kondisi jaringan normal\n",
    "  - UPSTREAM_FAILURE: Kegagalan uplink\n",
    "  - LINK_FAILURE: Kegagalan link\n",
    "  - DDOS_ATTACK: Serangan DDoS\n",
    "  - BROADCAST_STORM: Broadcast storm\n",
    "\n",
    "Contoh Rule yang BENAR (yang kita inginkan):\n",
    "- IF `ether1=down AND queue=high` THEN `LINK_FAILURE` ✓\n",
    "\n",
    "Contoh Rule yang SALAH (yang kita buang):\n",
    "- IF `LINK_FAILURE` THEN `ether1=down` ✗\n",
    "\n",
    "### Metrik Evaluasi\n",
    "- **Support**: Seberapa sering pola ini muncul dalam dataset (0-1)\n",
    "- **Confidence**: Probabilitas consequent terjadi jika antecedent terjadi (0-1)\n",
    "- **Lift**: Seberapa kuat hubungan antara antecedent dan consequent (>1 = hubungan positif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15793906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 4: FILTERING RULES =====\n",
    "# Definisikan label diagnosis yang valid\n",
    "DIAGNOSIS_LABELS = ['NORMAL', 'UPSTREAM_FAILURE', 'LINK_FAILURE', 'DDOS_ATTACK', 'BROADCAST_STORM']\n",
    "\n",
    "# Fungsi untuk mengecek apakah consequent mengandung diagnosis\n",
    "def is_diagnosis(consequents):\n",
    "    \"\"\"\n",
    "    Cek apakah consequents (frozenset) mengandung minimal 1 label diagnosis\n",
    "    \"\"\"\n",
    "    return any(label in consequents for label in DIAGNOSIS_LABELS)\n",
    "\n",
    "# Filter rules - hanya ambil yang berakhir dengan diagnosis\n",
    "final_rules = rules[rules['consequents'].apply(is_diagnosis)].copy()\n",
    "print(f\"✓ Rules setelah filtering:\")\n",
    "print(f\"  - Total rules sebelum filter: {len(rules)}\")\n",
    "print(f\"  - Rules dengan diagnosis consequent: {len(final_rules)}\")\n",
    "print(f\"  - Rules yang dihilangkan: {len(rules) - len(final_rules)}\")\n",
    "\n",
    "# ===== STEP 5: SORTING =====\n",
    "# Urutkan berdasarkan confidence (tertinggi) kemudian support (tertinggi)\n",
    "final_rules = final_rules.sort_values(['confidence', 'support'], ascending=[False, False])\n",
    "print(f\"\\n✓ Rules sudah diurutkan berdasarkan confidence dan support (descending)\")\n",
    "\n",
    "# ===== STEP 6: DISPLAY HASIL =====\n",
    "# Pilih kolom yang akan ditampilkan\n",
    "final_rules_display = final_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"TOP 10 ASSOCIATION RULES - NETWORK ANOMALY DETECTION\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "# Tampilkan dengan format yang lebih rapi\n",
    "for idx, (i, row) in enumerate(final_rules_display.head(10).iterrows(), 1):\n",
    "    antecedents = ', '.join(list(row['antecedents']))\n",
    "    consequents = ', '.join(list(row['consequents']))\n",
    "    \n",
    "    print(f\"[Rule {idx}]\")\n",
    "    print(f\"  IF:   {antecedents}\")\n",
    "    print(f\"  THEN: {consequents}\")\n",
    "    print(f\"  Support: {row['support']:.4f} | Confidence: {row['confidence']:.4f} | Lift: {row['lift']:.4f}\")\n",
    "    print()\n",
    "\n",
    "# ===== STEP 7: SAVE HASIL =====\n",
    "# Simpan top 10 rules ke CSV\n",
    "final_rules_display.head(10).to_csv('../Final_Skripsi_Rules.csv', index=False)\n",
    "print(f\"{'='*100}\")\n",
    "print(f\"✓ Top 10 rules berhasil disimpan ke 'Final_Skripsi_Rules.csv'\")\n",
    "print(f\"{'='*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc1373",
   "metadata": {},
   "source": [
    "## Kesimpulan dan Interpretasi\n",
    "\n",
    "### Hasil Analisis\n",
    "Notebook ini menghasilkan association rules yang menunjukkan hubungan antara kondisi jaringan dan tipe anomali. Setiap rule memiliki:\n",
    "- **Antecedents (IF)**: Kondisi atau kombinasi kondisi jaringan yang diamati\n",
    "- **Consequents (THEN)**: Diagnosis/prediksi tipe anomali yang kemungkinan terjadi\n",
    "- **Confidence**: Tingkat akurasi prediksi (semakin tinggi semakin baik)\n",
    "- **Support**: Seberapa sering pola ini muncul dalam data (frekuensi)\n",
    "- **Lift**: Seberapa kuat hubungan antara kondisi dan diagnosis\n",
    "\n",
    "### Penggunaan Praktis\n",
    "Hasil rules ini dapat digunakan untuk:\n",
    "1. **Early Warning System**: Mendeteksi anomali sebelum terjadi dengan mengecek kondisi antecedent\n",
    "2. **Root Cause Analysis**: Memahami faktor-faktor apa yang menyebabkan setiap tipe anomali\n",
    "3. **Network Optimization**: Meningkatkan monitoring dan maintenance protokol berdasarkan insights\n",
    "4. **Decision Support**: Membantu network administrator membuat keputusan yang lebih cepat dan tepat\n",
    "\n",
    "### File Output\n",
    "- **Final_Skripsi_Rules.csv**: Berisi top 10 rules dalam format CSV yang dapat digunakan untuk proses selanjutnya"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
